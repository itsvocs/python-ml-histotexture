{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 4: Machine Learning Klassifikation\n",
    "\n",
    "**Ziel:**\n",
    "- Decision Tree Classifier auf 3 Features trainieren\n",
    "- Feature Importance visualisieren\n",
    "- Modell-Performance evaluieren\n",
    "\n",
    "**Projektanforderung:**\n",
    "> Trainieren Sie einen einfachen Decision Tree Classifier auf den drei Features und visualisieren Sie, an welchem Feature die erste Aufteilung erfolgt.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports & Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn for Machine Learning\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries importiert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfade\n",
    "PROCESSED_DIR = Path('../data/processed')\n",
    "RESULTS_DIR = Path('../results/figures')\n",
    "MODELS_DIR = Path('../results/models')\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# DataFrame laden\n",
    "df = pd.read_csv(PROCESSED_DIR / 'features_with_labels.csv')\n",
    "\n",
    "print(f\"Dataset geladen: {len(df)} Bilder\")\n",
    "print(f\"\\nLabel-Verteilung:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Daten vorbereiten\n",
    "\n",
    "Wir brauchen:\n",
    "- X: Features (Entropie, Varianz, Median)\n",
    "- y: Labels (0 = Normal, 1 = Tumor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (X) und Labels (y) vorbereiten\n",
    "feature_columns = ['entropy', 'variance', 'median']\n",
    "X = df[feature_columns].values\n",
    "y = df['label_is_malignant'].values  # 0 = Normal, 1 = Tumor\n",
    "\n",
    "print(\"Daten vorbereitet:\")\n",
    "print(f\"  X shape: {X.shape}  (Anzahl Samples × Anzahl Features)\")\n",
    "print(f\"  y shape: {y.shape}  (Anzahl Labels)\")\n",
    "print(f\"\\nFeature-Matrix (erste 5 Zeilen):\")\n",
    "print(X[:5])\n",
    "print(f\"\\nLabels (erste 10):\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3,      # 30% für Test\n",
    "    random_state=42,    # Reproduzierbarkeit\n",
    "    stratify=y          # Gleiche Label-Verteilung in Train und Test\n",
    ")\n",
    "\n",
    "print(\"Train-Test Split:\")\n",
    "print(f\"  Training: {len(X_train)} Samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Test:     {len(X_test)} Samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nLabel-Verteilung im Training-Set:\")\n",
    "print(f\"  Normal (0): {np.sum(y_train == 0)} Samples\")\n",
    "print(f\"  Tumor (1):  {np.sum(y_train == 1)} Samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision Tree Classifier trainieren\n",
    "\n",
    "**Was ist ein Decision Tree?**\n",
    "- Baumstruktur für Klassifikation\n",
    "- Jeder Knoten = eine Entscheidung basierend auf einem Feature\n",
    "- Blätter = finale Klassifikation (Tumor oder Normal)\n",
    "\n",
    "**Vorteil:** Sehr interpretierbar - wir können sehen, welche Features wichtig sind!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree erstellen\n",
    "clf = DecisionTreeClassifier(\n",
    "    max_depth=3,           # Maximale Tiefe = 3 Levels\n",
    "    random_state=42,       # Reproduzierbarkeit\n",
    "    min_samples_split=4,   # Minimum 4 Samples für Split\n",
    "    min_samples_leaf=2     # Minimum 2 Samples pro Blatt\n",
    ")\n",
    "\n",
    "# Modell trainieren\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Decision Tree trainiert\")\n",
    "print(f\"\\nModell-Parameter:\")\n",
    "print(f\"  Max Depth: {clf.max_depth}\")\n",
    "print(f\"  Actual Depth: {clf.get_depth()}\")\n",
    "print(f\"  Number of Leaves: {clf.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modell evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen auf Test-Set\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy berechnen\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Modell-Performance:\")\n",
    "print(f\"  Training Accuracy: {train_accuracy:.3f} ({train_accuracy*100:.1f}%)\")\n",
    "print(f\"  Test Accuracy:     {test_accuracy:.3f} ({test_accuracy*100:.1f}%)\")\n",
    "\n",
    "if train_accuracy - test_accuracy > 0.1:\n",
    "    print(\"\\nHinweis: Große Differenz zwischen Train und Test → mögliches Overfitting\")\n",
    "else:\n",
    "    print(\"\\nGute Generalisierung - ähnliche Performance auf Train und Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detaillierter Classification Report\n",
    "print(\"Classification Report (Test-Set):\\n\")\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    y_pred_test,\n",
    "    target_names=['Normal', 'Tumor']\n",
    "))\n",
    "\n",
    "print(\"Metriken erklärt:\")\n",
    "print(\"  Precision: Von allen als Tumor vorhergesagten, wie viele sind wirklich Tumor?\")\n",
    "print(\"  Recall: Von allen echten Tumoren, wie viele wurden erkannt?\")\n",
    "print(\"  F1-Score: Harmonisches Mittel von Precision und Recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=['Normal', 'Tumor'],\n",
    "    yticklabels=['Normal', 'Tumor'],\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '14_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion Matrix erklärt:\")\n",
    "print(f\"  True Negatives (TN):  {cm[0,0]} - Korrekt als Normal erkannt\")\n",
    "print(f\"  False Positives (FP): {cm[0,1]} - Fälschlich als Tumor erkannt\")\n",
    "print(f\"  False Negatives (FN): {cm[1,0]} - Fälschlich als Normal erkannt\")\n",
    "print(f\"  True Positives (TP):  {cm[1,1]} - Korrekt als Tumor erkannt\")\n",
    "print(f\"\\nPlot gespeichert: results/figures/14_confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PROJEKTANFORDERUNG: Feature Importance visualisieren\n",
    "\n",
    "Zeigt, welches Feature am wichtigsten für die Klassifikation ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance extrahieren\n",
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "for i, (feature, importance) in enumerate(zip(feature_columns, feature_importance)):\n",
    "    print(f\"  {feature:10s}: {importance:.4f} ({importance*100:.1f}%)\")\n",
    "\n",
    "# Wichtigstes Feature identifizieren\n",
    "most_important_idx = np.argmax(feature_importance)\n",
    "print(f\"\\nWichtigstes Feature: {feature_columns[most_important_idx]}\")\n",
    "print(\"Dieses Feature wird für die erste Aufteilung im Baum verwendet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance als Barplot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = ['red' if i == most_important_idx else 'steelblue' for i in range(len(feature_columns))]\n",
    "\n",
    "bars = ax.bar(feature_columns, feature_importance, color=colors, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Werte auf Balken anzeigen\n",
    "for bar, importance in zip(bars, feature_importance):\n",
    "    height = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width()/2.,\n",
    "        height + 0.02,\n",
    "        f'{importance:.3f}\\n({importance*100:.1f}%)',\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=11,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Features', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Importance', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Feature Importance im Decision Tree', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, max(feature_importance) * 1.2)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '15_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"PROJEKTANFORDERUNG erfüllt\")\n",
    "print(f\"Plot gespeichert: results/figures/15_feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Decision Tree visualisieren\n",
    "\n",
    "Zeigt die Struktur des Baumes - welche Splits werden gemacht?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree visualisieren\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "\n",
    "plot_tree(\n",
    "    clf,\n",
    "    feature_names=feature_columns,\n",
    "    class_names=['Normal', 'Tumor'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_title('Decision Tree Struktur', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '16_decision_tree_structure.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Tree-Visualisierung gespeichert: results/figures/16_decision_tree_structure.png\")\n",
    "print(\"\\nWie man den Baum liest:\")\n",
    "print(\"  - Oberster Knoten (root): Erste Aufteilung\")\n",
    "print(\"  - Jeder Knoten zeigt: Feature, Threshold, Samples, Klassen-Verteilung\")\n",
    "print(\"  - Farbe: Orange = mehr Tumor, Blau = mehr Normal\")\n",
    "print(\"  - Blätter (unten): Finale Vorhersage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Modell speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell als pickle-Datei speichern\n",
    "model_path = MODELS_DIR / 'decision_tree_classifier.pkl'\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "print(f\"Modell gespeichert: {model_path}\")\n",
    "print(\"\\nDas Modell kann später geladen werden mit:\")\n",
    "print(\"  with open('model.pkl', 'rb') as f:\")\n",
    "print(\"      clf = pickle.load(f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Zusammenfassung Teil 4\n",
    "\n",
    "### Was wir erreicht haben:\n",
    "\n",
    "1. Decision Tree Classifier trainiert auf 3 Features\n",
    "2. Modell-Performance evaluiert:\n",
    "   - Accuracy, Precision, Recall, F1-Score\n",
    "   - Confusion Matrix\n",
    "3. **Feature Importance analysiert** (Projektanforderung erfüllt)\n",
    "4. Tree-Struktur visualisiert\n",
    "5. Modell gespeichert\n",
    "\n",
    "### Erkenntnisse:\n",
    "\n",
    "**Welches Feature ist am wichtigsten?**\n",
    "- Siehe Feature Importance Plot\n",
    "- Dieses Feature wird für die erste Aufteilung verwendet\n",
    "\n",
    "**Wie gut funktioniert das Modell?**\n",
    "- Test Accuracy zeigt Generalisierung\n",
    "- Confusion Matrix zeigt, wo Fehler gemacht werden\n",
    "\n",
    "**Für die Präsentation:**\n",
    "- Feature Importance Plot → zeigt wichtigstes Feature\n",
    "- Tree-Visualisierung → zeigt Entscheidungslogik\n",
    "- Confusion Matrix → zeigt Performance\n",
    "\n",
    "---\n",
    "\n",
    "### ALLE 4 PROJEKTTEILE KOMPLETT\n",
    "\n",
    "**Teil 1:** Farbraum-Analyse\n",
    "**Teil 2:** Feature-Extraktion\n",
    "**Teil 3:** Statistische Analyse & Visualisierung\n",
    "**Teil 4:** Machine Learning Klassifikation\n",
    "\n",
    "### Nächste Schritte:\n",
    "\n",
    "1. Code aufräumen und dokumentieren\n",
    "2. Alle Plots für Präsentation sammeln\n",
    "3. README aktualisieren mit Ergebnissen\n",
    "4. Präsentation vorbereiten\n",
    "\n",
    "---\n",
    "\n",
    "**Status:** PROJEKT KOMPLETT\n",
    "\n",
    "**Bereit für:** Code-Review und Präsentationsvorbereitung\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
